{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make job and Start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file ID: file-GL4Dph8hEPjLTz4hdLPgiw\n",
      "Fine-tuning job ID: ftjob-OuonNJHsEjO1TeN5aaxlMyAB\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: validating_files\n",
      "Fine-tuning status: running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_status\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# 완료되면 루프 종료\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 1분마다 상태 확인 (API 호출 제한 방지)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Load API key from file\n",
    "with open('./env/key.json') as f:\n",
    "    auth_key = json.load(f)\n",
    "    openai.api_key = auth_key['gpt']\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"fine_tuning.log\",  # Log file name\n",
    "    level=logging.INFO,          # Log level (INFO and above)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # Log format\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Function to log and print messages\n",
    "def log_and_print(message):\n",
    "    print(message)\n",
    "    logging.info(message)\n",
    "\n",
    "# Upload data file for fine-tuning\n",
    "response = openai.files.create(\n",
    "    file=open(\"tunedata.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "file_id = response.id\n",
    "log_and_print(f\"Uploaded file ID: {file_id}\")\n",
    "\n",
    "# Start fine-tuning job\n",
    "tune_response = openai.fine_tuning.jobs.create(\n",
    "    training_file=file_id,\n",
    "    model=\"gpt-4o-2024-08-06\"\n",
    ")\n",
    "job_id = tune_response.id\n",
    "log_and_print(f\"Fine-tuning job ID: {job_id}\")\n",
    "\n",
    "# Monitor fine-tuning job status\n",
    "while True:\n",
    "    job_status = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "    log_and_print(f\"Fine-tuning status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
    "        break  # Exit loop when job is complete\n",
    "    \n",
    "    time.sleep(30)  # Check status every 30 seconds (to avoid API rate limits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check fine-tuning information (eg. model name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-OuonNJHsEjO1TeN5aaxlMyAB', created_at=1739413873, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-2024-08-06:personal::B0KHkpXT', finished_at=1739417675, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-5PCocf2RmwF68HWSPyxRPqwE', result_files=['file-HsXN7a7nqTbWtgpdi2r4Fg'], seed=412734729, status='succeeded', trained_tokens=882159, training_file='file-GL4Dph8hEPjLTz4hdLPgiw', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3)), type='supervised'), user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "job_id = 'ftjob-OuonNJHsEjO1TeN5aaxlMyAB'  # Example job ID\n",
    "\n",
    "# Retrieve fine-tuning job information\n",
    "job_info = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = job_info\n",
    "print(fine_tuned_model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check training step and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739417691 - info: The job has successfully completed\n",
      "1739417677 - info: New fine-tuned model created\n",
      "1739417677 - info: Checkpoint created at step 1020\n",
      "1739417677 - info: Checkpoint created at step 510\n",
      "1739417663 - info: Step 1530/1530: training loss=0.20\n",
      "1739417661 - info: Step 1529/1530: training loss=0.31\n",
      "1739417659 - info: Step 1528/1530: training loss=1.73\n",
      "1739417657 - info: Step 1527/1530: training loss=0.48\n",
      "1739417655 - info: Step 1526/1530: training loss=0.00\n",
      "1739417653 - info: Step 1525/1530: training loss=0.23\n",
      "1739417651 - info: Step 1524/1530: training loss=0.32\n",
      "1739417649 - info: Step 1523/1530: training loss=0.43\n",
      "1739417645 - info: Step 1522/1530: training loss=0.98\n",
      "1739417643 - info: Step 1521/1530: training loss=0.60\n",
      "1739417640 - info: Step 1520/1530: training loss=0.78\n",
      "1739417638 - info: Step 1519/1530: training loss=0.13\n",
      "1739417636 - info: Step 1518/1530: training loss=0.30\n",
      "1739417634 - info: Step 1517/1530: training loss=0.09\n",
      "1739417632 - info: Step 1516/1530: training loss=0.00\n",
      "1739417630 - info: Step 1515/1530: training loss=0.00\n"
     ]
    }
   ],
   "source": [
    "# List fine-tuning job events\n",
    "log_response = openai.fine_tuning.jobs.list_events(job_id)\n",
    "for event in log_response.data:\n",
    "    print(f\"{event.created_at} - {event.level}: {event.message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dataset Randomly (too much data & too much invalid dataset (violate Openai usage policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플링된 515개의 줄을 tunedata.jsonl에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"fine_tune_data.jsonl\"   # Original jsonl file\n",
    "output_file = \"tunedata.jsonl\" # Sampled jsonl file\n",
    "\n",
    "# Read JSONL file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [json.loads(line) for line in f]\n",
    "\n",
    "# Randomly sample 1/3 of the data\n",
    "sample_size = len(lines) // 3\n",
    "sampled_lines = random.sample(lines, sample_size)\n",
    "\n",
    "# Save the sampled data to a new jsonl file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in sampled_lines:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"샘플링된 {sample_size}개의 줄을 {output_file}에 저장했습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}